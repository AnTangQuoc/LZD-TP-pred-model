---
title: Model Development and Apparent Validation
---

```{r}
source("notebooks/initialize-data-analysis.r")
source("notebooks/BMA-model-no-initial-var.r") # run_bas_glm() function
```

```{r}
multi_model <- data_patient_complete |>
  select(all_of(predictor_list), flag_ADR_TP_ID) |>
  run_bas_glm(
    formula = flag_ADR_TP_ID ~ .
  )

summary(multi_model)
plot(multi_model)
image(multi_model, rotate = FALSE)
diagnostics(multi_model)

multi_predict_HPM <- variable.names(predict(multi_model, estimator = "HPM"))[-1] |>
  str_extract(paste(predictor_list, collapse = "|")) # highest probability model
multi_predict_BPM <- variable.names(predict(multi_model, estimator = "BPM"))[-1] |>
  str_extract(paste(predictor_list, collapse = "|")) # best predictive model, this model is weird
```

```{r}
library(tidymodels)

data_patient_complete_response_as_factor <- data_patient_complete |>
  mutate(
    flag_ADR_TP_ID = as.factor(flag_ADR_TP_ID)
  )

model_full <- logistic_reg() |>
  set_engine("glm") |>
  set_mode("classification") |>
  fit(
    reformulate(
      termlabels = multi_predict_HPM,
      response = "flag_ADR_TP_ID"
    ),
    data = data_patient_complete_response_as_factor
  )
```

```{r}
library(CalibrationCurves)
pHat <- predict(model_full$fit, data_patient_complete, type = "response")
yTest <- data_patient_complete$flag_ADR_TP_ID
calperf <- valProbggplot(pHat, yTest)

apparent_performance_metrics <- tibble(
  apparent_C_index = calperf$Cindex[[1]],
  apparent_calibration_intercept = calperf$Calibration$Intercept[[1]],
  apparent_calibration_slope = calperf$Calibration$Slope[[1]]
)

save(apparent_performance_metrics, file = "data/model-performance/apparent-performance-metrics.rda")
```

```{r}
save(model_full, file = "data/model-performance/model-full.rda")
```