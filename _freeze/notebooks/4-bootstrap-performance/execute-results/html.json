{
  "hash": "05f3e8e12506964870518ce1c772b886",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Bootstrap Development and Validation\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsource(\"notebooks/initialize-data-analysis.r\", local = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nRows: 5669 Columns: 113\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (4): patient_ID, site, dept, LZD_route\ndbl  (20): patient_age, patient_weight, charlson, baseline_CLCR, baseline_WB...\nlgl  (85): patient_sex, dept_ICU, dept_ER, dept_other, invasive_ETI, invasiv...\ndate  (4): baseline_date, LZD_start, LZD_end, test_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 780 Columns: 105\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (4): patient_ID, site, dept, LZD_route\ndbl  (13): patient_age, patient_weight, charlson, baseline_CLCR, baseline_WB...\nlgl  (85): patient_sex, dept_ICU, dept_ER, dept_other, invasive_ETI, invasiv...\ndate  (3): baseline_date, LZD_start, LZD_end\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(BAS)\nlibrary(rsample) # for bootstraps()\nlibrary(furrr) # for future_map()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: future\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n✔ broom        1.0.5     ✔ recipes      1.0.9\n✔ dials        1.2.0     ✔ tune         1.1.2\n✔ infer        1.0.5     ✔ workflows    1.1.3\n✔ modeldata    1.3.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.1     ✔ yardstick    1.3.0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(CalibrationCurves)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: rms\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: Hmisc\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'Hmisc'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:parsnip':\n\n    translate\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following objects are masked from 'package:dplyr':\n\n    src, summarize\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\ndata_patient_bootstrap_prep <- data_patient_complete |>\n  select(all_of(predictor_list), flag_ADR_TP_ID)\n\n# Create 500 bootstrap samples\nboot_samples <- bootstraps(data_patient_bootstrap_prep, times = 30)\n\nrun_bas_glm <- function(data, formula, family, ...) {\n  bas.glm(formula, data = data, family = family, ...)\n}\n\nextract_variable_names <- function(sample) {\n  data <- analysis(sample)\n  model <- data |>\n    run_bas_glm(\n      formula = flag_ADR_TP_ID ~ .,\n      family = binomial(),\n      MCMC.iterations = 100000,\n      method = \"MCMC\"\n    )\n  variable.names(predict(model, estimator = \"HPM\"))[-1] |>\n    str_extract(paste(predictor_list, collapse = \"|\"))\n}\n\n# Function to modify sample data and fit model\nfit_model_to_sample <- function(sample, variables) {\n  data <- analysis(sample) |>\n    mutate(flag_ADR_TP_ID = as.factor(flag_ADR_TP_ID))\n\n  formula <- reformulate(termlabels = variables, response = \"flag_ADR_TP_ID\")\n\n  logistic_reg() |>\n    set_engine(\"glm\") |>\n    set_mode(\"classification\") |>\n    fit(formula, data = data)\n}\n\ncalc_boot_performance <- function(sample, model) {\n  data <- analysis(sample)\n  pHat <- predict(model$fit, data, type = \"response\")\n  yTest <- data$flag_ADR_TP_ID\n  calperf <- valProbggplot(pHat, yTest, smooth = \"none\")\n\n  tibble(\n    boot_C_index = calperf$Cindex[[1]],\n    boot_calibration_intercept = calperf$Calibration$Intercept[[1]],\n    boot_calibration_slope = calperf$Calibration$Slope[[1]]\n  )\n}\n\ncalc_test_performance <- function(model) {\n  pHat <- predict(model$fit, data_patient_complete, type = \"response\")\n  yTest <- data_patient_complete$flag_ADR_TP_ID\n  calperf <- valProbggplot(pHat, yTest, smooth = \"none\")\n\n  tibble(\n    test_C_index = calperf$Cindex[[1]],\n    test_calibration_intercept = calperf$Calibration$Intercept[[1]],\n    test_calibration_slope = calperf$Calibration$Slope[[1]]\n  )\n}\n\n# Set up future to use multiple cores\nplan(multisession, workers = min(parallel::detectCores() - 2, 10))\n\nboot_predict_HPM <- boot_samples$splits |>\n  future_map(extract_variable_names, .options = furrr_options(seed = TRUE))\n\n# Fit model to each sample in parallel\nboot_full <- future_map2(boot_samples$splits, boot_predict_HPM, fit_model_to_sample)\n\nboot_performance_metrics <- future_map2_dfr(boot_samples$splits, boot_full, calc_boot_performance)\n\n# Calculate performance metrics for each model in parallel\ntest_performance_metrics <- boot_full |>\n  future_map_dfr(calc_test_performance)\n\nplan(sequential)\n\n# Combine performance metrics\nperformance_metrics <- bind_cols(boot_performance_metrics, test_performance_metrics)\n\n# Calculate optimism\nperformance_metrics <- performance_metrics |>\n  mutate(\n    optimism_C_index = boot_C_index - test_C_index,\n    optimism_calibration_intercept = boot_calibration_intercept - test_calibration_intercept,\n    optimism_calibration_slope = boot_calibration_slope - test_calibration_slope\n  )\n\noptimism_estimates <- performance_metrics |>\n  summarise(\n    mean_optimism_C_index = mean(optimism_C_index),\n    mean_optimism_calibration_intercept = mean(optimism_calibration_intercept),\n    mean_optimism_calibration_slope = mean(optimism_calibration_slope)\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nload(\"data/model-performance/model_full.rda\")\n\npHat <- predict(model_full$fit, data_patient_complete, type = \"response\")\nyTest <- data_patient_complete$flag_ADR_TP_ID\ncalperf <- valProbggplot(pHat, yTest)\n\napparent_performance_metrics <- tibble(\n  apparent_C_index = calperf$Cindex[[1]],\n  apparent_calibration_intercept = calperf$Calibration$Intercept[[1]],\n  apparent_calibration_slope = calperf$Calibration$Slope[[1]]\n)\n\ncorrected_performance_metrics <- bind_cols(apparent_performance_metrics, optimism_estimates) |>\n  mutate(\n    corrected_C_index = apparent_C_index - mean_optimism_C_index,\n    corrected_calibration_intercept = apparent_calibration_intercept - mean_optimism_calibration_intercept,\n    corrected_calibration_slope = apparent_calibration_slope - mean_optimism_calibration_slope\n  ) |>\n  select(starts_with(\"corrected\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsave(corrected_performance_metrics, file = \"data/model-performance/corrected_performance_metrics.rda\")\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}