---
title: Development and Validation of a Risk Prediction Model of linezolid-induced thrombocytopenia

authors:
  - name: Nhi Nguyen Ha
    affiliation: The National DI&ADR Centre, Hanoi University of Pharmacy
    roles: writing
    corresponding: false
  - name: An Tang Quoc
    affiliation: The National DI&ADR Centre, Hanoi University of Pharmacy
    roles: writing
    corresponding: false
  - name: Ha Tran Ngan
    affiliation: The National DI&ADR Centre, Hanoi University of Pharmacy
    roles: writing
    corresponding: false
  - name: Hang Nguyen Thi Thu
    affiliation: The National DI&ADR Centre, Hanoi University of Pharmacy
    roles: writing
    corresponding: false 
  - name: Hoa Vu Dinh
    affiliation: The National DI&ADR Centre, Hanoi University of Pharmacy
    roles: writing
    corresponding: false 
  - name: Nhung TH Trinh
    affiliation: Pharmacoepidemiology and Drug Safety Research Group, Department of Pharmacy, Faculty of Mathematics and Natural Sciences, University of Oslo, Oslo, Norway
    roles: writing
    corresponding: false
  - name: Anh Nguyen Hoang
    affiliation: The National DI&ADR Centre, Hanoi University of Pharmacy
    roles: writing
    corresponding: true
# bibliography: references.bib

css: styles.css

abstract: |
  Write abstract here,
  note the indentation
---

# Checklist

| **Section/topic**                   | **Item No** | **Description**                                                                                                                                                                                                                        | **Draft date** |
|------------------|:----------------:|-------------------|:----------------:|
| **Title and abstract**              |             |                                                                                                                                                                                                                                        |                |
| Title                               |      1      | Identify the study as developing and/or validating a multivariable prediction model, the target population, and the outcome to be predicted                                                                                            |                |
| Abstract                            |      2      | Provide a summary of research objectives, setting, participants, data source, sample size, predictors, outcome, statistical analysis, results, and conclusions\*                                                                       |                |
| **Introduction**                    |             |                                                                                                                                                                                                                                        |                |
| Background and objectives           |     3a      | Explain the medical context (including whether diagnostic or prognostic) and rationale for developing or validating the prediction model, including references to existing models, and the advantages of the study design\*            |                |
|                                     |     3b      | Specify the objectives, including whether the study describes the development or validation of the model\*                                                                                                                             |                |
| **Methods**                         |             |                                                                                                                                                                                                                                        |                |
| Participants and data               |     4a      | Describe eligibility criteria for participants and datasets\*                                                                                                                                                                          |                |
|                                     |     4b      | Describe the origin of the data, and how the data were identified, requested, and collected                                                                                                                                            |                |
| Sample size                         |      5      | Explain how the sample size was arrived at\*                                                                                                                                                                                           |     Mar 21     |
| Outcomes and predictors             |     6a      | Define the outcome that is predicted by the model, including how and when assessed\*                                                                                                                                                   |     Mar 21     |
|                                     |     6b      | Define all predictors used in developing or validating the model, including how and when measured\*                                                                                                                                    |                |
| Data preparation                    |     7a      | Describe how the data were prepared for analysis, including any cleaning, harmonisation, linkage, and quality checks                                                                                                                   |                |
|                                     |     7b      | Describe the method for assessing risk of bias and applicability in the individual clusters (eg, using PROBAST)                                                                                                                        |                |
|                                     |     7c      | For validation, identify any differences in definition and measurement from the development data (eg, setting, eligibility criteria, outcome, predictors)\*                                                                            |                |
|                                     |     7d      | Describe how missing data were handled\*                                                                                                                                                                                               |                |
| Data analysis                       |     8a      | Describe how predictors were handled in the analyses                                                                                                                                                                                   |                |
|                                     |     8b      | Specify the type of model, all model building procedures (eg, any predictor selection and penalisation), and method for validation\*                                                                                                   |                |
|                                     |     8c      | Describe how any heterogeneity across clusters (eg, studies or settings) in model parameter values was handled                                                                                                                         |                |
|                                     |     8d      | For validation, describe how the predictions were calculated                                                                                                                                                                           |                |
|                                     |     8e      | Specify all measures used to assess model performance (eg, calibration, discrimination, and decision curve analysis) and, if relevant, to compare multiple models                                                                      |                |
|                                     |     8f      | Describe how any heterogeneity across clusters (eg, studies or settings) in model performance was handled and quantified                                                                                                               |                |
|                                     |     8g      | Describe any model updating (eg, recalibration) arising from the validation, either overall or for particular populations or settings\*                                                                                                |                |
| Sensitivity analysis                |      9      | Describe any planned subgroup or sensitivity analysisâ€”eg, assessing performance according to sources of bias, participant characteristics, setting                                                                                     |                |
| **Results**                         |             |                                                                                                                                                                                                                                        |                |
| Participants and datasets           |     10a     | Describe the number of clusters and participants from data identified through to data analysed; a flowchart might be helpful\*                                                                                                         |                |
|                                     |     10b     | Report the characteristics overall and where applicable for each data source or setting, including the key dates, predictors, treatments received, sample size, number of outcome events, follow-up time, and amount of missing data\* |                |
|                                     |     10c     | For validation, show a comparison with the development data of the distribution of important variables (demographics, predictors, and outcome)                                                                                         |                |
| Risk of bias                        |     11      | Report the results of the risk-of-bias assessment in the individual clusters                                                                                                                                                           |                |
| Model development and specification |     12a     | Report the results of any assessments of heterogeneity across clusters that led to subsequent actions during the modelâ€™s development (eg, inclusion or exclusion of particular predictors or clusters)                                 |                |
|                                     |     12b     | Present the final prediction model (ie, all regression coefficients, and model intercept or baseline estimate of the outcome at a given time point) and explain how to use it for predictions in new individuals\*                     |                |
| Model performance                   |     13a     | Report performance measures (with uncertainty intervals) for the prediction model, overall and for each cluster                                                                                                                        |                |
|                                     |     13b     | Report results of any heterogeneity across clusters in model performance                                                                                                                                                               |                |
| Model updating                      |     14      | Report the results from any model updating (including the updated model equation and subsequent performance), overall and for each cluster\*                                                                                           |                |
| Sensitivity analysis                |     15      | Report results from any subgroup or sensitivity analysis                                                                                                                                                                               |                |
| **Discussion**                      |             |                                                                                                                                                                                                                                        |                |
| Interpretation                      |     16a     | Give an overall interpretation of the main results, including heterogeneity across clusters in model performance, in the context of the objectives and previous studies\*                                                              |                |
|                                     |     16b     | For validation, discuss the results with reference to the model performance in the development data, and in any previous validations                                                                                                   |                |
|                                     |     16c     | Discuss the strengths of the study and any limitations (eg, missing or incomplete data, non-representativeness, data harmonisation problems)                                                                                           |                |
| Implications                        |     17      | Discuss the potential use of the model and implications for future research, with specific view to generalisability and applicability of the model across different settings or (sub)populations                                       |                |
| **Other information**               |             |                                                                                                                                                                                                                                        |                |
| Supplementary information           |     18      | Provide information about the availability of supplementary resources (eg, study protocol, analysis code, datasets)\*                                                                                                                  |                |
| Funding                             |     19      | Give the source of funding and the role of the funders for the present study                                                                                                                                                           |                |

: TRIPOD-Cluster checklist of items to include when reporting a study developing or validating a multivariable prediction model using clustered data {tbl-colwidths = "\[20, 10, 60, 10\]"}

# Introduction

## Background and objectives

**First paragraph:** introduction about linezolid and associated ADR including thrombocytopenia

**Second paragraph:** what is already known in the literature about this association (magnitude and associated factors)

**Third paragraph:** the importance of investigation this association in Vietnamese settings and develop a risk prediction model. Why is this study needed?

This study aimed to develop and validate a risk prediction model of linezolid-induced thrombocytopenia adapted to Vietnamese setting. In addition, we constructed a simplified risk score using this model to enhance the applicability of the prediction rule in clinical practice.

# Methods

## Participants and data

### 4a: Describe eligibility criteria for participants and datasets

This study used data from three tertiary hospitals in Northern Vietnam: Thanh Nhan Hospital, Bach Mai Hospital, and the National Hospital of Tropical Diseases. Patients hospitalized and treated with linezolid were included. The following patients were excluded: (i) those under 18 years of age; (ii) those treated with linezolid for less than 3 days; (iii) those without any recorded platelet count in the period before or after initiation of linezolid therapy; (iv) those with baseline platelet count of \> 450 x 10^9^ cells/L; (v) those with any missing recorded values among the specified predictors. Each patient was included only once per admission and the first linezolid treatment course was evaluated. Included patients were followed up until the end of the linezolid treatment course or discharge date whichever comes first.

### 4b: Describe the origin of the data, and how the data were identified, requested, and collected

The data was collected from each hospital in two phases: a pilot phase and an extension phase. In the pilot phase, we requested existing datasets at the hospitals. In the extension phase, additional data was collected prospectively. Data was extracted from the electronic medical records of the hospitals, except for the pilot dataset at Bach Mai Hospital which was extracted from physical records. In order to harmonise different datasets, data was filled out in a paper form and stored in Excel.

The pilot datasets were collected from January 01 to June 30, 2020 at Thanh Nhan Hospital; from November 01 to December 31, 2019 at Bach Mai Hospital; from May 01 to December 31, 2021 at the National Hospital of Tropical Diseases. The extension datasets were collected from September 01, 2022 to March 31, 2023 at Thanh Nhan Hospital; from December 01, 2022 to March 31, 2023 at Bach Mai Hospital; from April 01 to September 31, 2022 at the National Hospital of Tropical Diseases. *(comment: no data of total number of patients admitted to these hospitals during each period)*

The anonymized data were extracted from electronical medical records at each medical institution, except data from Bach Mai Hospital in the pilot phase. Individual ID number were assigned to each patient's hospital admission.

Ethical approval was obtained from....

## Sample size

Previous studies developing logistic regression models for LI-TP risk predictions have included 4-6 predictors in their final models [@liu_analysis_2021; @duan_regression_2022; @qin_development_2021; @xu_establishment_2023]. We expect to include about as many candidate predictors, based on results from the expert opinion survey and the Bayesian Model Selection algorithm [see @sec-outcomes-and-predictors]. Some of the candidate predictors might be continuous, which may potentially require non-linear modelling and therefore slightly increase the number of variables.

A general rule of thumb is for at least 10 events be available for each candidate predictor considered in a prediction model @peduzzi1995. We have a total of 816 eligible patients and 264 of those have experienced the outcome. If the number of candidate predictors is 7, we would have 37 events per candidate predictor, which is considerably greater than the minimum number required. Even if the number of parameters screened is 20, we would still have 13 events per candidate predictor.

However, the aforementioned rule of thumb have generated some debate in the literature, with recent results suggesting that event per variable criterion is too simplistic and has no strong relation to the predictive performance of a model. Riley et al @riley2019 proposed a different set of criteria to estimate minimum sample size for models developed using logistic regression, which are the following:

1.  Small optimism in predictor effect estimates, defined as a global shrinkage factor of \>= 0.9.
2.  Small absolute difference of \<= 0.05 in the model's apparent and adjusted Nagelkerke's R-squared.
3.  Precise estimation of the overall risk in the population.

Criteria 1 and 2 aims to reduce the potential of overfitting. Criteria 3 aims to ensure the overall risk is estimated precisely.

### Step 1: Choose the number of candidate predictors of interest for inclusion in the model, and calculate the corresponding number of predictor parameters (p)

Note that one predictor may require two or more parameters. For example, a k-category predictor requires k-1 parameters and a continuous predictor model with a non-linear trend requires more than one parameter to be estimated. Also include any potential interaction terms towards the total p.

When using a predictor selection method, p should be defined as the total number of parameters screened, and not just the subset that are included in the final model.

Assuming maximum total p to be 20.

::: callout-note
The value of p is assumed to be no larger than 20 because univariate regression shows there are 20 variables that are significantly correlated with the outcome.
:::

```{r}
parameter_number <- 20
sample_size <- 816
```

### Step 2: Choose sensible values for R^2^~CS_adj~ and max(R^2^~CS_app~) based on previous studies where R^2^~CS~ is the Cox-Snell R^2^ statistic.

The value of max(R^2^~CS_app~) is based on the overall prevalence or overall rate of the outcome in the population of interest. The incidence of LI-TP in patients treated with linezolid was estimated to be 37% in a meta-analysis by Zhao et al @zhao_prediction_2024.

The value of R^2^~CS_adj~ could be based on that for a previously published model in the same setting and population (with similar outcome definition). However, as previous studies does not provide any information to identify a sensible value of the minimum expected Cox-Snell R^2^, the value R^2^~CS_adj~ will be assumed to correspond to a R^2^~Nagelkerke~ of 0.50, as baseline platelet count, a "direct" measurement of the outcome, is likely to be a predictor.

```{r}
calculate_R2_CS_adj <- function(n = 100, E, R2_N = 0.15) {
  ln_L_null <- E * log(E / n) + (n - E) * log(1 - E / n)
  max_R2_CS_app <- 1 - exp(2 * ln_L_null / n)
  R2_CS_adj <- R2_N / max_R2_CS_app
  return(list(R2_CS_adj = R2_CS_adj, max_R2_CS_app = max_R2_CS_app))
}

(cox_snell_r2 <- calculate_R2_CS_adj(E = 37)$R2_CS_adj)
max_apparent_cox_snell_r2 <- calculate_R2_CS_adj(E = 37)$max_R2_CS_app
```

### Step 3: Criterion 1

Calculate the sample size required to ensure Van Houwelingen's global shrinkage factor (S~VH~) is close to 1. A value of S~VH~ \>= 0.90 is generally recommended, which reflects a small amount of overfitting during model development.

```{r}
calculate_sample_size_1 <- function(p, R2_CS_adj, S_VH = 0.90) {
  n <- p / ((S_VH - 1) * log(1 - R2_CS_adj / S_VH))
  return(n)
}

(
  sample_size_criterion_1 <-
    calculate_sample_size_1(
      p = parameter_number,
      R2_CS_adj = cox_snell_r2
    ) |> ceiling()
)

calculate_param_limit_1 <- function(n, R2_CS_adj, S_VH = 0.90) {
  p <- n * ((S_VH - 1) * log(1 - R2_CS_adj / S_VH))
  return(p)
}

(
  parameter_limit_1 <- calculate_param_limit_1(
    n = sample_size,
    R2_CS_adj = cox_snell_r2
  ) |> floor()
)

```

We see that `r sample_size_criterion_1` participants are required to meet criterion 1.

### Step 4: Criterion 2

Calculate the shrinkage factor (S~VH~) required to ensure a small absolute difference of \<= 0.05 in the developed model's apparent and adjusted Nagelkerke's R^2^. Then derive the required sample size conditional on this value of S~VH~.

```{r}
calculate_sample_size_2 <- function(p, R2_CS_adj, max_R2_CS_app, delta = 0.05) {
  S_VH <- R2_CS_adj / (R2_CS_adj + delta * max_R2_CS_app)
  n <- p / ((S_VH - 1) * log(1 - R2_CS_adj / S_VH))
  return(n)
}

(
  sample_size_criterion_2 <-
    calculate_sample_size_2(
      p = parameter_number,
      R2_CS_adj = cox_snell_r2,
      max_R2_CS_app = max_apparent_cox_snell_r2
    ) |> ceiling()
)

calculate_param_limit_2 <- function(n, R2_CS_adj, max_R2_CS_app, delta = 0.05) {
  S_VH <- R2_CS_adj / (R2_CS_adj + delta * max_R2_CS_app)
  p <- n * ((S_VH - 1) * log(1 - R2_CS_adj / S_VH))
  return(p)
}

(
  parameter_limit_2 <- calculate_param_limit_2(
    n = sample_size,
    R2_CS_adj = cox_snell_r2,
    max_R2_CS_app = max_apparent_cox_snell_r2
  ) |> floor()
) 

```

We see that `r sample_size_criterion_2` participants are required to meet criterion 2.

### Step 5: Criterion 3

Calculate the sample size required to ensure a precise estimate of the overall risk in the population. The suggested absolute margin of error is \<= 0.05.

```{r}
calculate_sample_size_3 <- function(phi_hat, delta = 0.05) {
  n <- (1.96 / delta)^2 * phi_hat * (1 - phi_hat)
  return(n)
}

(
  sample_size_criterion_3 <-
    calculate_sample_size_3(phi_hat = 0.37) |> ceiling()
)
```

We see that `r sample_size_criterion_3` participants are required to meet criterion 3.

### Step 6: Final sample size

The required minimum sample size is the maximum value from steps 3 to 5, to ensure that each of criteria 1 to 3 are met.

```{r}
(minimum_sample_size <- max(sample_size_criterion_1, sample_size_criterion_2, sample_size_criterion_3))
(maximum_parameter_limit <- min(parameter_limit_1, parameter_limit_2))
```

The final estimate of minimum sample size is `r minimum_sample_size`, therefore our data is sufficient for model development with 20 parameters.

The maximum number of parameters that can be screened is `r maximum_parameter_limit`.

## Outcomes and predictors {#sec-outcomes-and-predictors}

### 6a. Define the outcome that is predicted by the model, including how and when assessed

The outcome of interest is linezolid-induced thrombocytopenia, defined as (i) a platelet count of \< 112.5 x 10^9^ cells/L (75% of the lower limit of normal) for patients with a baseline platelet count in the normal range; (ii) A reduction in platelet count of â‰¥ 25% from the baseline value for patients with a baseline platelet count of \< 150 x 10^9^ cells/L [@zyvoxpr; @xu_establishment_2023; @kawasuji_proposal_2021].

Normal platelet count is defined as 150-450 x 10^9^ cells/L. Baseline platelet count is defined as the last recorded PLT value before the start of linezolid therapy. Participants are considered to have met the outcome if their platelet count value meets the above criteria at any time during linezolid therapy or within 5 days after the end of therapy.

::: callout-warning
Thrombocytopenia may occur within a few days after stopping LZD, when the drug hasn't been completely eliminated. However, it is unknown exactly how long after stopping LZD can a TP event still be attributed to LZD use. We deemed that any TP events that occur after 5 days of stopping LZD would not be related to LZD use.

Our rationale is that after 5 days (120 hrs), LZD is guaranteed to be completely eliminated in all patients, as the longest t~1/2~ is 8.3 Â± 2.4 hrs in end-stage renal disease patients, +3 SD would be \~16 hrs, so 120 hrs is \>7 half-lives, therefore in patients with the worst clearance, 99% of them would have 99% of the drug eliminated from their systems. Furthermore, trough LZD concentration (C~min~) has previously been identified as a predictor of LI-TP development, and LI-TP itself is mostly reversible after discontinuation, so we would argue that any TP events that occur after LZD has been eliminated from the system would not be related to LZD use.
:::

### 6b. Define all predictors used in developing or validating the model, including how and when measured

Predictors will be screened for inclusion in the model if they meet all of the following criteria: (i) has been identified as a risk factor of LI-TP in previous studies; (ii) can be collected or evaluated from the information in the datasets; (iii) for concomitant medications, has drug-induced immune thrombocytopenia as an adverse drug reaction with a frequency of at least \> 1/1000 in the drug label or Micromedex; (iv) has consensus from a clinical expert panel as possibly related to LI-TP development.

The following information was extracted from all records:

-   Patient demographics
-   Clinical department where linezolid was initiated.
-   Co-morbidities
-   Invasive procedures performed
-   Infection type
-   Laboratory results
-   Linezolid route of administration
-   Linezolid dose in milligrams.
-   Linezolid duration, defined as the number of days from the first to the last dose of linezolid.
-   Concomitant medications during linezolid therapy

## Data preparation

### 7a. Describe how the data were prepared for analysis, including any cleaning, harmonisation, linkage, and quality checks

Harmonisation between datasets was mainly done via manually recording data to a standardized form. Data was then entered into an Excel spreadsheet. Data cleaning was done by handling duplicates, checking for missing values and inconsistencies. Multiple linezolid treatment episodes in the same patient were treated as duplicates and only the first episode was included in the analysis. Patients with missing values were excluded from subsequent analyses. Inconsistencies were resolved by referring back to the original records.

Before analysis, the extracted predictors are limited to those that meet criteria (i) to (iii) in the previous section:

-   Patient demographics were limited to age in years, gender, and weight in kilograms.
-   Clinical department was recorded into binary variables: intensive care unit, emergency department, and others.
-   Co-morbidities were recorded into binary variables: hypertension, heart failure, angina, myocardial infarction, cerebral vascular accident, diabetes, chronic obstructive pulmonary disease, cirrhosis, malignancies, and hematological disorders.
-   Invasive procedures were recorded into binary variables: endotracheal intubation, central venous catheter insertion, intermittent hemodialysis, and continuous renal replacement therapy.
-   Infection type was recorded into binary variables: community-acquired pneumonia, hospital-acquired pneumonia, skin and soft tissue infection, central nervous system infection, intra-abdominal infection, urinary tract infection, bone and joint infection, septicemia, and sepsis.
-   Laboratory results were limited to serum creatinine, hemoglobin count, white blood cell count, and platelet count. Creatinine clearance was estimated from serum creatinine using the Cockcroft-Gault equation.
-   Linezolid route of administration was recorded into binary variables: intravenous, oral, and both.
-   Linezolid dose in milligrams.
-   Linezolid duration in days.
-   Concomitant medications were recoded to binary variables: carbapenems, daptomycin, teicoplanin, levofloxacin, ibuprofen, naproxen, heparin, clopidogrel, enoxaparin, eptifibatide, carbamazepine, valproic acid, quetiapine, atezolizumab, pembrolizumab, trastuzumab, tacrolimus, fluorouracil, irinotecan, leucovorin, oxaliplatin, pyrazinamide, and rifampin.

### 7b. Describe the method for assessing risk of bias and applicability in the individual clusters (eg, using PROBAST)

::: callout-important
Is this even possible for this study?
:::

### 7c. For validation, identify any differences in definition and measurement from the development data (eg, setting, eligibility criteria, outcome, predictors)

### 7d. Describe how missing data were handled

Any subsequent analyses were conducted on the complete case dataset. There are \~5% of observations with missing values in the dataset, which is considered low. The missing data mechanism is assumed to be missing completely at random.

::: callout-important
What is a possible reason for missing data?
:::

## Data analysis

### 8a. Describe how predictors were handled in the analyses

### 8b. Specify the type of model, all model building procedures (eg, any predictor selection and penalisation), and method for validation

### 8c. Describe how any heterogeneity across clusters (eg, studies or settings) in model parameter values was handled

### 8d. For validation, describe how the predictions were calculated

### 8e. Specify all measures used to assess model performance (eg, calibration, discrimination, and decision curve analysis) and, if relevant, to compare multiple models

### 8f. Describe how any heterogeneity across clusters (eg, studies or settings) in model performance was handled and quantified

### 8g. Describe any model updating (eg, recalibration) arising from the validation, either overall or for particular populations or settings

## Sensitivity analysis

# Results

## Participants and datasets

## Risk of bias

## Model development and specification

## Model performance

## Model updating

## Sensitivity analysis

# Discussion

## Interpretation

## Implications

# Other information

## Supplementary information

## Funding

## References

::: {#refs}
:::